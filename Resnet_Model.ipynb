{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c7b73c8-f77a-4f0b-947d-5bf377320c81",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import json\n",
    "import os\n",
    "from tqdm import tqdm, tqdm_notebook\n",
    "import random\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential, Model\n",
    "from tensorflow.keras.layers import *\n",
    "from tensorflow.keras.optimizers import *\n",
    "from tensorflow.keras.applications import *\n",
    "from tensorflow.keras.callbacks import *\n",
    "from tensorflow.keras.initializers import *\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c7b5b16-c646-4e50-8518-0e1da4f9f087",
   "metadata": {},
   "outputs": [],
   "source": [
    "#seeds:\n",
    "np.random.seed(123)\n",
    "tf.random.set_seed(123)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "174a3ad6-09a6-4530-87fd-76f3613dd2d2",
   "metadata": {},
   "source": [
    "# Data Loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d23e8b8f-47e1-45a8-934e-1fef659f3392",
   "metadata": {},
   "outputs": [],
   "source": [
    "artists = pd.read_csv('./Data/artists.csv', sep=\",\")\n",
    "print(\"The number of painting is {}.\".format(artists.shape[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33c80b6d-d8c1-4a50-9399-5edb69041cea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sort artists by number of paintings\n",
    "artists = artists.sort_values(by=['paintings'], ascending=False)\n",
    "\n",
    "# Create a dataframe with artists having more than 200 paintings\n",
    "artists_top = artists[artists['paintings'] >= 200].reset_index()\n",
    "artists_top = artists_top[['name', 'paintings']]\n",
    "#artists_top['class_weight'] = max(artists_top.paintings)/artists_top.paintings\n",
    "artists_top['class_weight'] = artists_top.paintings.sum() / (artists_top.shape[0] * artists_top.paintings)\n",
    "artists_top"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "186a46bd-40dd-4869-b0b4-6ef010052982",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set class weights - assign higher weights to underrepresented classes\n",
    "class_weights = artists_top['class_weight'].to_dict()\n",
    "class_weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e3ce192-71d4-40cd-9383-f41395c31002",
   "metadata": {},
   "outputs": [],
   "source": [
    "updated_name = \"Albrecht_Dürer\".replace(\"_\", \" \")\n",
    "artists_top.iloc[4, 0] = updated_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40918b6b-49be-454d-bfbc-61959088dd76",
   "metadata": {},
   "outputs": [],
   "source": [
    "artists_top_name = artists_top['name'].str.replace(' ', '_').values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0fc3ee72-2800-43dc-9069-dcf4aa872e80",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a DataFrame to store filename and artist mapping\n",
    "file_artist_mapping = []\n",
    "\n",
    "for filename in os.listdir(images_dir):\n",
    "    if filename.endswith(('.png', '.jpg', '.jpeg')):\n",
    "        artist_name = \" \".join(filename.split(\"_\")[:-1])\n",
    "        file_artist_mapping.append({'filename': filename, 'artist': artist_name})\n",
    "\n",
    "df = pd.DataFrame(file_artist_mapping)\n",
    "\n",
    "# Remove rows where the artist is 'Albrecht Du╠êrer'\n",
    "df = df[df['artist'] != 'Albrecht Du╠êrer']\n",
    "\n",
    "# Get unique artist names\n",
    "artists = df['artist'].unique()\n",
    "n_classes = len(artists)\n",
    "\n",
    "# Define image size and other parameters\n",
    "img_size = (224, 224)\n",
    "batch_size = 16\n",
    "\n",
    "# Create data generators\n",
    "datagen = ImageDataGenerator(validation_split=0.2,\n",
    "                                   rescale=1./255.,\n",
    "                                   #rotation_range=45,\n",
    "                                   #width_shift_range=0.5,\n",
    "                                   #height_shift_range=0.5,\n",
    "                                   shear_range=5,\n",
    "                                   #zoom_range=0.7,\n",
    "                                   horizontal_flip=True,\n",
    "                                   vertical_flip=True,)\n",
    "\n",
    "train_generator = datagen.flow_from_dataframe(\n",
    "    dataframe=df,\n",
    "    directory=images_dir,\n",
    "    x_col='filename',\n",
    "    y_col='artist',\n",
    "    target_size=img_size,\n",
    "    batch_size=batch_size,\n",
    "    class_mode='categorical',\n",
    "    subset='training',\n",
    "    classes=artists_top_name.tolist()\n",
    ")\n",
    "\n",
    "validation_generator = datagen.flow_from_dataframe(\n",
    "    dataframe=df,\n",
    "    directory=images_dir,\n",
    "    x_col='filename',\n",
    "    y_col='artist',\n",
    "    target_size=img_size,\n",
    "    batch_size=batch_size,\n",
    "    class_mode='categorical',\n",
    "    subset='validation',\n",
    "    classes=artists_top_name.tolist()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c64bacf-6062-4224-89a1-55c2b2552128",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(1, 2, figsize=(20,10))\n",
    "\n",
    "random_artist = random.choice(artists_top_name)\n",
    "random_image = random.choice(os.listdir(os.path.join(images_dir)))\n",
    "random_image_file = os.path.join(images_dir, random_image)\n",
    "image = plt.imread(random_image_file)\n",
    "axes[0].imshow(image)\n",
    "axes[0].set_title(\"An original Image of \" + random_artist.replace('_', ' '))\n",
    "axes[0].axis('off')\n",
    "aug_image = datagen.random_transform(image)\n",
    "axes[1].imshow(aug_image)\n",
    "axes[1].set_title(\"A transformed Image of \" + random_artist.replace('_', ' '))\n",
    "axes[1].axis('off')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2e4fe8d-d1aa-4d47-9591-4211c94313d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_input_shape = (224, 224, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a212b4d0-1ca7-4ede-bf4a-2bba4ba0230a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load pre-trained model\n",
    "base_model = ResNet50(weights='imagenet', include_top=False, input_shape=train_input_shape)\n",
    "\n",
    "for layer in base_model.layers:\n",
    "    layer.trainable = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "587b35e7-3ad4-4971-aa5c-37a7f24499da",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add layers at the end\n",
    "X = base_model.output\n",
    "X = Flatten()(X)\n",
    "\n",
    "X = Dense(512, kernel_initializer='he_uniform')(X)\n",
    "#X = Dropout(0.5)(X)\n",
    "X = BatchNormalization()(X)\n",
    "X = Activation('relu')(X)\n",
    "\n",
    "X = Dense(16, kernel_initializer='he_uniform')(X)\n",
    "#X = Dropout(0.5)(X)\n",
    "X = BatchNormalization()(X)\n",
    "X = Activation('relu')(X)\n",
    "\n",
    "output = Dense(n_classes, activation='softmax')(X)\n",
    "\n",
    "model = Model(inputs=base_model.input, outputs=output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8be93e7-56b0-425e-9636-f46897c79447",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = tf.keras.optimizers.legacy.Adam(lr=0.0001)\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer=optimizer, \n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ae38089-1c2e-4a31-b02e-b4211fb71d52",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_epoch = 10\n",
    "\n",
    "early_stop = EarlyStopping(monitor='val_loss', patience=20, verbose=1, \n",
    "                           mode='auto', restore_best_weights=True)\n",
    "\n",
    "reduce_lr = ReduceLROnPlateau(monitor='val_loss', factor=0.1, patience=5, \n",
    "                              verbose=1, mode='auto')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3768d265-c3c2-4fe6-bac5-3dc7c05f3eb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "STEP_SIZE_TRAIN = train_generator.n//train_generator.batch_size\n",
    "STEP_SIZE_VALID = validation_generator.n//validation_generator.batch_size\n",
    "print(\"Total number of batches =\", STEP_SIZE_TRAIN, \"and\", STEP_SIZE_VALID)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ed7b166-6364-435f-9cd5-699525950a69",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train the model - all layers\n",
    "history1 = model.fit_generator(generator=train_generator, steps_per_epoch=STEP_SIZE_TRAIN,\n",
    "                              validation_data=validation_generator, validation_steps=STEP_SIZE_VALID,\n",
    "                              epochs=n_epoch,\n",
    "                              shuffle=True,\n",
    "                              verbose=1,\n",
    "                              callbacks=[reduce_lr],\n",
    "                              use_multiprocessing=True,\n",
    "                              workers=16,\n",
    "                              class_weight=class_weights\n",
    "                             )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f62e0dfa-d9b6-45e8-8f0b-82ffc185b81c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "images_dir = './Data/resized'\n",
    "artists_dirs = list(set([\" \".join(filename.split(\"_\")[:-1]) for filename in os.listdir(images_dir)])) #get all names from /resized\n",
    "n_classes = len(artists_dirs)\n",
    "print(artists_dirs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfb10b64-815d-4dc4-9a95-cafc0d002b90",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56215e82-a6d6-4574-bd64-9f597675aaa9",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(artists_dirs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c69b6f7e-451a-449d-87c6-f712e4e80b7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Correct the data quality issue with Albrecht Dürer\n",
    "artists_dirs.remove('Albrecht Du╠êrer')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a13d9894-027f-408a-9dcf-0ad5f9f25f14",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(artists_dirs))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec23aa08-b6e1-4e58-b858-0ad27d85097e",
   "metadata": {},
   "source": [
    "# Data Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b2cd953-5e76-48d1-aade-dab26d3a938c",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(18,5))\n",
    "\n",
    "sns.barplot(x=artist_df['nationality'].value_counts().index,y=artist_df['nationality'].value_counts().values)\n",
    "plt.title('nationality')\n",
    "plt.xticks(rotation=75)\n",
    "plt.ylabel('Rates')\n",
    "plt.legend(loc=0)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25d3e0cc-0c6f-498e-974a-d5dc5e6f310c",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(18,5))\n",
    "sns.barplot(x=artist_df['genre'].value_counts().index,\n",
    "              y=artist_df['genre'].value_counts().values)\n",
    "plt.xlabel('genre')\n",
    "plt.xticks(rotation=75)\n",
    "plt.ylabel('Frequency')\n",
    "plt.title('Show of genre Bar Plot')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7db9c52a-816a-4d99-9c72-3f11c33716c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(1, 5, figsize=(20,10))\n",
    "\n",
    "for i in range(5):\n",
    "    random_image = random.choice(os.listdir(os.path.join(images_dir)))\n",
    "    random_image_file = os.path.join(images_dir, random_image)\n",
    "    image = plt.imread(random_image_file)\n",
    "    axes[i].imshow(image)\n",
    "    axes[i].set_title(\"Image: \" + random_image)\n",
    "    axes[i].axis('off')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c805af2f-b591-47bf-b2e2-71460e508fe6",
   "metadata": {},
   "source": [
    "# Train and Test Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "167b77bc-9dab-4452-a612-9407dae6fe23",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a DataFrame to store filename and artist mapping\n",
    "file_artist_mapping = []\n",
    "\n",
    "for filename in os.listdir(images_dir):\n",
    "    if filename.endswith(('.png', '.jpg', '.jpeg')):\n",
    "        artist_name = \" \".join(filename.split(\"_\")[:-1])\n",
    "        file_artist_mapping.append({'filename': filename, 'artist': artist_name})\n",
    "\n",
    "df = pd.DataFrame(file_artist_mapping)\n",
    "\n",
    "# Remove rows where the artist is 'Albrecht Du╠êrer'\n",
    "df = df[df['artist'] != 'Albrecht Du╠êrer']\n",
    "\n",
    "# Get unique artist names\n",
    "artists = df['artist'].unique()\n",
    "n_classes = len(artists)\n",
    "\n",
    "# Define image size and other parameters\n",
    "img_size = (128, 128)\n",
    "batch_size = 32\n",
    "\n",
    "# Create data generators\n",
    "datagen = ImageDataGenerator(rescale=1./255, validation_split=0.2)\n",
    "\n",
    "train_generator = datagen.flow_from_dataframe(\n",
    "    dataframe=df,\n",
    "    directory=images_dir,\n",
    "    x_col='filename',\n",
    "    y_col='artist',\n",
    "    target_size=img_size,\n",
    "    batch_size=batch_size,\n",
    "    class_mode='categorical',\n",
    "    subset='training'\n",
    ")\n",
    "\n",
    "validation_generator = datagen.flow_from_dataframe(\n",
    "    dataframe=df,\n",
    "    directory=images_dir,\n",
    "    x_col='filename',\n",
    "    y_col='artist',\n",
    "    target_size=img_size,\n",
    "    batch_size=batch_size,\n",
    "    class_mode='categorical',\n",
    "    subset='validation'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0d34da9-e1ca-4519-bfc4-772b38c2aede",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "378780c9-8cb0-4acc-8df0-8543f2c67d34",
   "metadata": {},
   "source": [
    "# Simple CNN Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c92c6270-b096-492c-a4b5-5d49aa385661",
   "metadata": {},
   "outputs": [],
   "source": [
    "def simple_cnn():\n",
    "    \n",
    "    # Build a simple CNN model\n",
    "    model = models.Sequential()\n",
    "    model.add(layers.Conv2D(32, (3, 3), activation='relu', input_shape=(img_size[0], img_size[1], 3)))\n",
    "    model.add(layers.MaxPooling2D((2, 2)))\n",
    "    model.add(layers.Conv2D(64, (3, 3), activation='relu'))\n",
    "    model.add(layers.MaxPooling2D((2, 2)))\n",
    "    model.add(layers.Conv2D(128, (3, 3), activation='relu'))\n",
    "    model.add(layers.MaxPooling2D((2, 2)))\n",
    "    model.add(layers.Flatten())\n",
    "    model.add(layers.Dense(128, activation='relu'))\n",
    "    model.add(layers.Dropout(0.5))\n",
    "    model.add(layers.Dense(n_classes, activation='softmax'))\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe80072c-5de0-413a-977d-bbaaff946d64",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Initialize model\n",
    "model= simple_cnn()\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Train the model\n",
    "history = model.fit(\n",
    "    train_generator,\n",
    "    epochs=20,\n",
    "    validation_data=validation_generator\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23770fd5-80aa-4d86-8979-fa90d6b5b174",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prediction accuracy on train data\n",
    "score = model.evaluate_generator(train_generator, verbose=1)\n",
    "print(\"Prediction accuracy on train data =\", score[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54320f6a-4e73-4e7f-aea9-7c77aa705f40",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prediction accuracy on CV data\n",
    "score = model.evaluate_generator(validation_generator, verbose=1)\n",
    "print(\"Prediction accuracy on CV data =\", score[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b26ccb2a-c864-4978-b85f-67f08fd67333",
   "metadata": {},
   "source": [
    "# Data Augmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3bfdb376-0176-4def-be56-387a570c7401",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a data generator with data augmentation\n",
    "datagen = ImageDataGenerator(\n",
    "    rescale=1./255,\n",
    "    shear_range=0.2,\n",
    "    zoom_range=0.2,\n",
    "    horizontal_flip=True,\n",
    "    validation_split=0.2\n",
    ")\n",
    "\n",
    "train_generator = datagen.flow_from_dataframe(\n",
    "    dataframe=df,\n",
    "    directory=images_dir,\n",
    "    x_col='filename',\n",
    "    y_col='artist',\n",
    "    target_size=img_size,\n",
    "    batch_size=batch_size,\n",
    "    class_mode='categorical',\n",
    "    subset='training'\n",
    ")\n",
    "\n",
    "validation_generator = datagen.flow_from_dataframe(\n",
    "    dataframe=df,\n",
    "    directory=images_dir,\n",
    "    x_col='filename',\n",
    "    y_col='artist',\n",
    "    target_size=img_size,\n",
    "    batch_size=batch_size,\n",
    "    class_mode='categorical',\n",
    "    subset='validation'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ba33eca-e7dd-4915-a51e-ab68e6cce576",
   "metadata": {},
   "outputs": [],
   "source": [
    "model= simple_cnn()\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Train the model\n",
    "history = model.fit(\n",
    "    train_generator,\n",
    "    epochs=20,\n",
    "    validation_data=validation_generator\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e49c0b5-fcf2-4d40-9313-41998ccfaa42",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prediction accuracy on train data\n",
    "score = model.evaluate_generator(train_generator, verbose=1)\n",
    "print(\"Prediction accuracy on train data =\", score[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0bd1885b-3277-4f26-ab99-f0c04833c626",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prediction accuracy on CV data\n",
    "score = model.evaluate_generator(validation_generator, verbose=1)\n",
    "print(\"Prediction accuracy on CV data =\", score[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d29d946-3e23-4412-9346-fb140fb46ebd",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
